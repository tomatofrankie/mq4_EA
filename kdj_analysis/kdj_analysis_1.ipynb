{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Interval = min K\n",
    "\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import stockstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['2023-02-06 00:00:00', '2023-02-07 00:00:00', '2023-02-08 00:00:00',\n",
       "       '2023-02-09 00:00:00', '2023-02-10 00:00:00', '2023-02-13 00:00:00',\n",
       "       '2023-02-14 00:00:00', '2023-02-15 00:00:00', '2023-02-16 00:00:00',\n",
       "       '2023-02-17 00:00:00', '2023-02-21 00:00:00', '2023-02-22 00:00:00',\n",
       "       '2023-02-23 00:00:00', '2023-02-24 00:00:00', '2023-02-27 00:00:00'],\n",
       "      dtype='object', name='Date Time')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime(2023,2,6,21)\n",
    "end_date = datetime(2023,2,28,1)\n",
    "data = yf.download('TSLA', interval = '1d', start = start_date ,end = end_date, auto_adjust = False)\n",
    "data.index.name = 'Date Time'\n",
    "data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[datetime.datetime(2023, 2, 7, 21, 0), datetime.datetime(2023, 2, 7, 23, 0)], [datetime.datetime(2023, 2, 8, 21, 0), datetime.datetime(2023, 2, 8, 23, 0)], [datetime.datetime(2023, 2, 9, 21, 0), datetime.datetime(2023, 2, 9, 23, 0)], [datetime.datetime(2023, 2, 10, 21, 0), datetime.datetime(2023, 2, 10, 23, 0)], [datetime.datetime(2023, 2, 13, 21, 0), datetime.datetime(2023, 2, 13, 23, 0)], [datetime.datetime(2023, 2, 14, 21, 0), datetime.datetime(2023, 2, 14, 23, 0)], [datetime.datetime(2023, 2, 15, 21, 0), datetime.datetime(2023, 2, 15, 23, 0)], [datetime.datetime(2023, 2, 16, 21, 0), datetime.datetime(2023, 2, 16, 23, 0)], [datetime.datetime(2023, 2, 17, 21, 0), datetime.datetime(2023, 2, 17, 23, 0)], [datetime.datetime(2023, 2, 21, 21, 0), datetime.datetime(2023, 2, 21, 23, 0)], [datetime.datetime(2023, 2, 22, 21, 0), datetime.datetime(2023, 2, 22, 23, 0)], [datetime.datetime(2023, 2, 23, 21, 0), datetime.datetime(2023, 2, 23, 23, 0)], [datetime.datetime(2023, 2, 24, 21, 0), datetime.datetime(2023, 2, 24, 23, 0)], [datetime.datetime(2023, 2, 27, 21, 0), datetime.datetime(2023, 2, 27, 23, 0)], [datetime.datetime(2023, 2, 28, 21, 0), datetime.datetime(2023, 2, 28, 23, 0)]]\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker = ['aapl','msft','amzn','nvda','tsla','goog','googl','meta','avgo']\n",
    "ticker = [x.upper() for x in ticker]\n",
    "weight = [12.16,11.93,6.09,4.8,3.93,3.6,3.59,3.4,2.09]\n",
    "weight_sum = sum(weight)\n",
    "\n",
    "# From 2/6 to 3/3\n",
    "date = [7,8,9,10,13,14,15,16,17,21,22,23,24,27,28]\n",
    "period = [[datetime(2023,2,i,21), datetime(2023,2,i,23)] for i in date]\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for k in period:\n",
    "    sep_stock = pd.DataFrame()\n",
    "\n",
    "    for i,j in enumerate(ticker):\n",
    "        start_date = k[0]\n",
    "        end_date = k[1]\n",
    "        data = yf.download(j, interval = '1m', start = start_date ,end = end_date, auto_adjust = False)\n",
    "        data.index.name = 'Date Time'\n",
    "        data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "        first_min = data.filter(like='09:30',axis=0)\n",
    "\n",
    "        stock = stockstats.StockDataFrame.retype(first_min)\n",
    "        kdj = stock.get(['kdjk','kdjd','kdjj'])\n",
    "\n",
    "        sep_stock[j] = kdj.iloc[0]\n",
    "\n",
    "    sep_stock = sep_stock.transpose()\n",
    "\n",
    "    sep_stock_sum = pd.DataFrame()\n",
    "\n",
    "    tmp = 0\n",
    "    for i,j in enumerate(weight):\n",
    "        tmp += sep_stock.iloc[i] * j / weight_sum\n",
    "    sep_stock_sum['Weighted Average'] = tmp\n",
    "\n",
    "    sep_stock_sum = sep_stock_sum.transpose()\n",
    "    \n",
    "    result = result.append(sep_stock_sum)\n",
    "\n",
    "\n",
    "result = result.drop_duplicates()\n",
    "result.index = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kdjk</th>\n",
       "      <th>kdjd</th>\n",
       "      <th>kdjj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51.646267</td>\n",
       "      <td>50.548756</td>\n",
       "      <td>53.841289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55.458254</td>\n",
       "      <td>51.819418</td>\n",
       "      <td>62.735926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42.257761</td>\n",
       "      <td>47.419254</td>\n",
       "      <td>31.934776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64.267536</td>\n",
       "      <td>54.755845</td>\n",
       "      <td>83.290918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43.048046</td>\n",
       "      <td>47.682682</td>\n",
       "      <td>33.778774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39.691651</td>\n",
       "      <td>46.563884</td>\n",
       "      <td>25.947185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54.527675</td>\n",
       "      <td>51.509225</td>\n",
       "      <td>60.564575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50.436939</td>\n",
       "      <td>50.145646</td>\n",
       "      <td>51.019524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55.328824</td>\n",
       "      <td>51.776275</td>\n",
       "      <td>62.433922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>49.395631</td>\n",
       "      <td>49.798544</td>\n",
       "      <td>48.589806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>53.950523</td>\n",
       "      <td>51.316841</td>\n",
       "      <td>59.217886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43.876279</td>\n",
       "      <td>47.958760</td>\n",
       "      <td>35.711318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50.886387</td>\n",
       "      <td>50.295462</td>\n",
       "      <td>52.068237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55.027580</td>\n",
       "      <td>51.675860</td>\n",
       "      <td>61.731021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>56.060337</td>\n",
       "      <td>52.020112</td>\n",
       "      <td>64.140786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         kdjk       kdjd       kdjj\n",
       "7   51.646267  50.548756  53.841289\n",
       "8   55.458254  51.819418  62.735926\n",
       "9   42.257761  47.419254  31.934776\n",
       "10  64.267536  54.755845  83.290918\n",
       "13  43.048046  47.682682  33.778774\n",
       "14  39.691651  46.563884  25.947185\n",
       "15  54.527675  51.509225  60.564575\n",
       "16  50.436939  50.145646  51.019524\n",
       "17  55.328824  51.776275  62.433922\n",
       "21  49.395631  49.798544  48.589806\n",
       "22  53.950523  51.316841  59.217886\n",
       "23  43.876279  47.958760  35.711318\n",
       "24  50.886387  50.295462  52.068237\n",
       "27  55.027580  51.675860  61.731021\n",
       "28  56.060337  52.020112  64.140786"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('feb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = ['aapl','msft','amzn','nvda','tsla','goog','googl','meta','avgo']\n",
    "# weight = [12.16,11.93,6.09,4.8,3.93,3.6,3.59,3.4,2.09]\n",
    "# weight_sum = sum(weight)\n",
    "# ticker = [x.upper() for x in ticker]\n",
    "\n",
    "# mon = pd.DataFrame()\n",
    "# tue = pd.DataFrame()\n",
    "# wed = pd.DataFrame()\n",
    "# thu = pd.DataFrame()\n",
    "# fri = pd.DataFrame()\n",
    "\n",
    "\n",
    "# for i,j in enumerate(ticker):\n",
    "#     start_date = datetime(2023, 2, 27, 21)\n",
    "#     end_date = datetime(2023, 3, 4, 16)\n",
    "#     data = yf.download(j, interval = '1m', start = start_date ,end = end_date, auto_adjust = False)\n",
    "#     data.index.name = 'Date Time'\n",
    "#     data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "#     first_min = data.filter(like='09:30',axis=0)\n",
    "\n",
    "#     stock = stockstats.StockDataFrame.retype(first_min)\n",
    "#     kdj = stock.get(['kdjk','kdjd','kdjj'])\n",
    "\n",
    "#     mon[j] = kdj.iloc[0]\n",
    "#     tue[j] = kdj.iloc[1]\n",
    "#     wed[j] = kdj.iloc[2]\n",
    "#     thu[j] = kdj.iloc[3]\n",
    "#     fri[j] = kdj.iloc[4]\n",
    "\n",
    "# mon = mon.transpose()\n",
    "# tue = tue.transpose()\n",
    "# wed = wed.transpose()\n",
    "# thu = thu.transpose()\n",
    "# fri = fri.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mon_sum = pd.DataFrame()\n",
    "# tue_sum = pd.DataFrame()\n",
    "# wed_sum = pd.DataFrame()\n",
    "# thu_sum = pd.DataFrame()\n",
    "# fri_sum = pd.DataFrame()\n",
    "\n",
    "# tmp = 0\n",
    "# for i,j in enumerate(weight):\n",
    "#    tmp += mon.iloc[i] * j / weight_sum\n",
    "# mon_sum = pd.DataFrame()\n",
    "# mon_sum['Weighted Average'] = tmp\n",
    "\n",
    "# tmp = 0\n",
    "# for i,j in enumerate(weight):\n",
    "#    tmp += tue.iloc[i] * j / weight_sum\n",
    "# tue_sum = pd.DataFrame()\n",
    "# tue_sum['Weighted Average'] = tmp\n",
    "\n",
    "# tmp = 0\n",
    "# for i,j in enumerate(weight):\n",
    "#    tmp += wed.iloc[i] * j / weight_sum\n",
    "# wed_sum = pd.DataFrame()\n",
    "# wed_sum['Weighted Average'] = tmp\n",
    "\n",
    "# tmp = 0\n",
    "# for i,j in enumerate(weight):\n",
    "#    tmp += thu.iloc[i] * j / weight_sum\n",
    "# thu_sum = pd.DataFrame()\n",
    "# thu_sum['Weighted Average'] = tmp\n",
    "\n",
    "# tmp = 0\n",
    "# for i,j in enumerate(weight):\n",
    "#    tmp += fri.iloc[i] * j / weight_sum\n",
    "# fri_sum = pd.DataFrame()\n",
    "# fri_sum['Weighted Average'] = tmp\n",
    "\n",
    "# mon_sum = mon_sum.transpose()\n",
    "# tue_sum = tue_sum.transpose()\n",
    "# wed_sum = wed_sum.transpose()\n",
    "# thu_sum = thu_sum.transpose()\n",
    "# fri_sum = fri_sum.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the CHANGE of .NDX of that day and Plot it\n",
    "\n",
    "# ticker = '^ndx'\n",
    "\n",
    "# start_date = datetime(2023, 2, 27, 21)\n",
    "# end_date = datetime(2023, 2, 27, 23)\n",
    "# data = yf.download(ticker, interval = '1m', start = start_date ,end = end_date, auto_adjust = False)\n",
    "# data.index.name = 'Date Time'\n",
    "# data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "# close = data['Close']\n",
    "# close = close[:-2]\n",
    "\n",
    "# close.plot()\n",
    "\n",
    "# mon_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = datetime(2023, 2, 28, 21)\n",
    "# end_date = datetime(2023, 2, 28, 23)\n",
    "# data = yf.download(ticker, interval = '1m', start = start_date ,end = end_date, auto_adjust = False)\n",
    "# data.index.name = 'Date Time'\n",
    "# data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "# close = data['Close']\n",
    "# close = close[:-2]\n",
    "\n",
    "# close.plot()\n",
    "\n",
    "# tue_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = datetime(2023, 3, 1, 21)\n",
    "# end_date = datetime(2023, 3, 1, 23)\n",
    "# data = yf.download(ticker, interval = '1m', start = start_date ,end = end_date, auto_adjust = False)\n",
    "# data.index.name = 'Date Time'\n",
    "# data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "# close = data['Close']\n",
    "# close = close[:-2]\n",
    "\n",
    "# close.plot()\n",
    "\n",
    "# wed_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = datetime(2023, 3, 2, 21)\n",
    "# end_date = datetime(2023, 3, 2, 23)\n",
    "# data = yf.download(ticker, interval = '1m', start = start_date ,end = end_date, auto_adjust = False)\n",
    "# data.index.name = 'Date Time'\n",
    "# data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "# close = data['Close']\n",
    "# close = close[:-2]\n",
    "\n",
    "# close.plot()\n",
    "\n",
    "# thu_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = datetime(2023, 3, 3, 21)\n",
    "# end_date = datetime(2023, 3, 3, 23)\n",
    "# data = yf.download(ticker, interval = '1m', start = start_date ,end = end_date, auto_adjust = False)\n",
    "# data.index.name = 'Date Time'\n",
    "# data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "# close = data['Close']\n",
    "# close = close[:-2]\n",
    "\n",
    "# close.plot()\n",
    "\n",
    "# fri_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker = ['aapl','msft','amzn','nvda','tsla','goog','googl','meta','avgo']\n",
    "# weight = [12.16,11.93,6.09,4.8,3.93,3.6,3.59,3.4,2.09]\n",
    "# weight_sum = sum(weight)\n",
    "# ticker = [x.upper() for x in ticker]\n",
    "# # From 2/6 to 3/3\n",
    "# period = [[datetime(2023, 2, 6, 21), datetime(2023, 2, 12, 16)],[datetime(2023, 2, 13, 21), datetime(2023, 2, 19, 16)],[datetime(2023, 2, 20, 21), datetime(2023, 2, 26, 16)],[datetime(2023, 2, 27, 21), datetime(2023, 3, 3, 16)]]\n",
    "\n",
    "\n",
    "\n",
    "# result = pd.DataFrame()\n",
    "\n",
    "# for k in period:\n",
    "#     mon = pd.DataFrame()\n",
    "#     tue = pd.DataFrame()\n",
    "#     wed = pd.DataFrame()\n",
    "#     thu = pd.DataFrame()\n",
    "#     fri = pd.DataFrame()\n",
    "\n",
    "#     for i,j in enumerate(ticker):\n",
    "#         start_date = k[0]\n",
    "#         end_date = k[1]\n",
    "#         data = yf.download(j, interval = '1m', start = start_date ,end = end_date, auto_adjust = False)\n",
    "#         data.index.name = 'Date Time'\n",
    "#         data.index = pd.to_datetime(data.index, format = '%m/%d/%Y').strftime('%Y-%m-%d %H:%M:%S')\n",
    "#         first_min = data.filter(like='09:30',axis=0)\n",
    "\n",
    "#         stock = stockstats.StockDataFrame.retype(first_min)\n",
    "#         kdj = stock.get(['kdjk','kdjd','kdjj'])\n",
    "\n",
    "#         try:\n",
    "#             mon[j] = kdj.iloc[0]\n",
    "#             tue[j] = kdj.iloc[1]\n",
    "#             wed[j] = kdj.iloc[2]\n",
    "#             thu[j] = kdj.iloc[3]\n",
    "#             fri[j] = kdj.iloc[4]\n",
    "#         except:\n",
    "#             continue\n",
    "#         else:\n",
    "#             mon[j] = kdj.iloc[0]\n",
    "#             tue[j] = kdj.iloc[1]\n",
    "#             wed[j] = kdj.iloc[2]\n",
    "#             thu[j] = kdj.iloc[3]\n",
    "\n",
    "#     try:\n",
    "#         mon = mon.transpose()\n",
    "#         tue = tue.transpose()\n",
    "#         wed = wed.transpose()\n",
    "#         thu = thu.transpose()\n",
    "#         fri = fri.transpose()\n",
    "\n",
    "#         mon_sum = pd.DataFrame()\n",
    "#         tue_sum = pd.DataFrame()\n",
    "#         wed_sum = pd.DataFrame()\n",
    "#         thu_sum = pd.DataFrame()\n",
    "#         fri_sum = pd.DataFrame()\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += mon.iloc[i] * j / weight_sum\n",
    "#         mon_sum['Weighted Average'] = tmp\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += tue.iloc[i] * j / weight_sum\n",
    "#         tue_sum['Weighted Average'] = tmp\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += wed.iloc[i] * j / weight_sum\n",
    "#         wed_sum['Weighted Average'] = tmp\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += thu.iloc[i] * j / weight_sum\n",
    "#         thu_sum['Weighted Average'] = tmp\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += fri.iloc[i] * j / weight_sum\n",
    "#         fri_sum['Weighted Average'] = tmp\n",
    "\n",
    "#         mon_sum = mon_sum.transpose()\n",
    "#         tue_sum = tue_sum.transpose()\n",
    "#         wed_sum = wed_sum.transpose()\n",
    "#         thu_sum = thu_sum.transpose()\n",
    "#         fri_sum = fri_sum.transpose()\n",
    "#         # print(mon_sum,tue_sum,wed_sum,thu_sum,fri_sum)\n",
    "        \n",
    "\n",
    "#         result = result.append(mon_sum)\n",
    "#         result = result.append(tue_sum)\n",
    "#         result = result.append(wed_sum)\n",
    "#         result = result.append(thu_sum)\n",
    "#         result = result.append(fri_sum)\n",
    "#     except:\n",
    "#         pass\n",
    "#     else:\n",
    "#         mon = mon.transpose()\n",
    "#         tue = tue.transpose()\n",
    "#         wed = wed.transpose()\n",
    "#         thu = thu.transpose()\n",
    "\n",
    "#         mon_sum = pd.DataFrame()\n",
    "#         tue_sum = pd.DataFrame()\n",
    "#         wed_sum = pd.DataFrame()\n",
    "#         thu_sum = pd.DataFrame()\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += mon.iloc[i] * j / weight_sum\n",
    "#         mon_sum['Weighted Average'] = tmp\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += tue.iloc[i] * j / weight_sum\n",
    "#         tue_sum['Weighted Average'] = tmp\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += wed.iloc[i] * j / weight_sum\n",
    "#         wed_sum['Weighted Average'] = tmp\n",
    "\n",
    "#         tmp = 0\n",
    "#         for i,j in enumerate(weight):\n",
    "#             tmp += thu.iloc[i] * j / weight_sum\n",
    "#         thu_sum['Weighted Average'] = tmp\n",
    "\n",
    "\n",
    "#         mon_sum = mon_sum.transpose()\n",
    "#         tue_sum = tue_sum.transpose()\n",
    "#         wed_sum = wed_sum.transpose()\n",
    "#         thu_sum = thu_sum.transpose()\n",
    "        \n",
    "\n",
    "#         result = result.append(mon_sum)\n",
    "#         result = result.append(tue_sum)\n",
    "#         result = result.append(wed_sum)\n",
    "#         result = result.append(thu_sum)\n",
    "\n",
    "#     result = result.drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
